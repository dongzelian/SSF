{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/hjy/SSF/')\n",
    "\n",
    "import torch\n",
    "\n",
    "from timm.models import create_model, safe_model_name, resume_checkpoint, load_checkpoint,\\\n",
    "    convert_splitbn_model, model_parameters\n",
    "from timm.utils import *\n",
    "from timm.loss import *\n",
    "\n",
    "from timm.scheduler import create_scheduler\n",
    "from timm.utils import ApexScaler, NativeScaler\n",
    "\n",
    "\n",
    "from data import create_loader, create_dataset\n",
    "from optim_factory import create_optimizer_v2, optimizer_kwargs\n",
    "\n",
    "from models import vision_transformer, swin_transformer, convnext, as_mlp\n",
    "\n",
    "import models.lora\n",
    "from models.lora import LoRA_ViT_timm\n",
    "## ADDED for Pruning\n",
    "import torch_pruning as tp\n",
    "from pruning.group_pruning import SSFScalePruner, BNScaleImportance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(\n",
    "        'vit_base_patch16_224_in21k',\n",
    "        pretrained=True,\n",
    "        num_classes=100,\n",
    "        drop_rate=0,\n",
    "        drop_path_rate=0,\n",
    "        global_pool=None,\n",
    "        bn_momentum=None,\n",
    "        bn_eps=None,\n",
    "        scriptable=False,\n",
    "        tuning_mode='ssf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 100])\n"
     ]
    }
   ],
   "source": [
    "img = torch.randn(2, 3, 224, 224)\n",
    "pred = model.forward(img)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VisionTransformer(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
      "    (norm): Identity()\n",
      "  )\n",
      "  (pos_drop): Dropout(p=0, inplace=False)\n",
      "  (blocks): Sequential(\n",
      "    (0): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0, inplace=False)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (1): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0, inplace=False)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (2): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0, inplace=False)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (3): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0, inplace=False)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (4): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0, inplace=False)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (5): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0, inplace=False)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (6): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0, inplace=False)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (7): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0, inplace=False)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (8): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0, inplace=False)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (9): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0, inplace=False)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (10): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0, inplace=False)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "    (11): Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0, inplace=False)\n",
      "      )\n",
      "      (ls1): Identity()\n",
      "      (drop_path1): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (drop1): Dropout(p=0, inplace=False)\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop2): Dropout(p=0, inplace=False)\n",
      "      )\n",
      "      (ls2): Identity()\n",
      "      (drop_path2): Identity()\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (fc_norm): Identity()\n",
      "  (head): Linear(in_features=768, out_features=100, bias=True)\n",
      ")\n",
      "Parameter containing:\n",
      "tensor([0.9794, 1.0154, 1.0009, 1.0065, 0.9886, 0.9753, 1.0018, 0.9917, 1.0199,\n",
      "        0.9991, 0.9750, 0.9717, 0.9982, 0.9749, 0.9822, 1.0149, 0.9787, 0.9891,\n",
      "        0.9827, 0.9811, 0.9871, 1.0286, 1.0018, 1.0043, 0.9916, 1.0424, 1.0075,\n",
      "        1.0045, 0.9824, 1.0030, 1.0152, 1.0349, 1.0064, 1.0355, 1.0232, 0.9906,\n",
      "        0.9997, 0.9840, 1.0040, 1.0043, 0.9655, 1.0243, 0.9834, 0.9885, 0.9883,\n",
      "        1.0294, 1.0167, 1.0209, 1.0059, 1.0045, 1.0103, 0.9977, 0.9770, 1.0080,\n",
      "        1.0197, 1.0097, 0.9927, 1.0408, 0.9925, 0.9827, 0.9911, 1.0312, 1.0007,\n",
      "        1.0046, 1.0039, 1.0164, 1.0046, 0.9810, 1.0121, 0.9946, 1.0006, 0.9949,\n",
      "        0.9923, 0.9943, 1.0018, 1.0041, 0.9868, 1.0240, 1.0076, 1.0076, 1.0020,\n",
      "        1.0040, 0.9774, 1.0001, 1.0044, 0.9918, 0.9987, 1.0016, 1.0152, 1.0055,\n",
      "        1.0048, 1.0356, 0.9818, 0.9876, 1.0215, 0.9848, 1.0130, 0.9759, 0.9981,\n",
      "        1.0199, 0.9756, 1.0011, 0.9898, 0.9834, 0.9946, 1.0075, 0.9778, 1.0147,\n",
      "        1.0230, 0.9900, 1.0132, 1.0020, 1.0046, 0.9681, 1.0024, 0.9955, 0.9604,\n",
      "        0.9583, 0.9998, 0.9904, 1.0442, 0.9990, 0.9834, 0.9897, 1.0191, 1.0364,\n",
      "        0.9977, 1.0119, 0.9791, 1.0109, 0.9707, 0.9928, 1.0102, 0.9913, 0.9763,\n",
      "        0.9849, 1.0210, 1.0027, 1.0310, 0.9763, 1.0257, 1.0421, 1.0016, 0.9635,\n",
      "        0.9841, 1.0125, 0.9694, 1.0040, 0.9945, 0.9954, 1.0205, 0.9538, 1.0029,\n",
      "        1.0087, 0.9846, 1.0184, 1.0008, 0.9730, 0.9940, 0.9979, 0.9985, 1.0108,\n",
      "        1.0138, 1.0478, 1.0021, 1.0132, 1.0115, 0.9915, 0.9906, 1.0011, 1.0139,\n",
      "        1.0022, 0.9817, 0.9864, 0.9878, 0.9746, 1.0158, 0.9904, 1.0142, 0.9844,\n",
      "        0.9827, 1.0262, 0.9986, 0.9838, 0.9709, 0.9923, 1.0020, 0.9987, 0.9997,\n",
      "        1.0176, 0.9941, 1.0249, 0.9997, 0.9992, 1.0326, 1.0027, 1.0088, 0.9784,\n",
      "        0.9820, 1.0227, 0.9839, 1.0030, 1.0083, 0.9973, 0.9830, 0.9713, 0.9720,\n",
      "        1.0220, 1.0390, 1.0357, 1.0278, 1.0163, 1.0326, 0.9924, 0.9963, 1.0219,\n",
      "        0.9987, 1.0027, 0.9982, 1.0448, 1.0072, 1.0190, 1.0032, 0.9883, 0.9991,\n",
      "        1.0113, 1.0169, 1.0009, 1.0114, 1.0091, 1.0109, 1.0117, 0.9900, 1.0139,\n",
      "        0.9837, 0.9917, 1.0082, 0.9987, 1.0197, 0.9946, 1.0136, 0.9941, 0.9847,\n",
      "        1.0061, 0.9785, 0.9858, 1.0014, 0.9945, 0.9826, 0.9862, 1.0289, 0.9981,\n",
      "        1.0356, 0.9909, 1.0153, 1.0262, 0.9850, 1.0198, 0.9783, 1.0007, 1.0131,\n",
      "        0.9864, 1.0233, 0.9988, 0.9863, 0.9889, 0.9932, 1.0174, 1.0382, 1.0040,\n",
      "        1.0056, 1.0040, 0.9892, 0.9929, 1.0210, 0.9803, 1.0138, 0.9853, 0.9954,\n",
      "        0.9917, 0.9687, 1.0158, 0.9793, 0.9893, 1.0086, 0.9953, 1.0124, 0.9876,\n",
      "        0.9814, 1.0043, 1.0206, 1.0154, 1.0056, 0.9832, 0.9926, 0.9957, 1.0139,\n",
      "        0.9831, 0.9847, 1.0108, 1.0117, 1.0011, 1.0012, 1.0174, 0.9936, 1.0251,\n",
      "        1.0070, 0.9859, 1.0154, 1.0190, 1.0068, 1.0119, 0.9731, 1.0084, 1.0013,\n",
      "        0.9821, 0.9844, 0.9673, 1.0144, 1.0200, 0.9808, 1.0028, 0.9916, 0.9942,\n",
      "        0.9953, 0.9821, 0.9829, 1.0209, 0.9792, 0.9974, 0.9825, 1.0347, 0.9724,\n",
      "        1.0305, 0.9983, 0.9839, 0.9993, 1.0551, 0.9693, 0.9848, 1.0065, 1.0441,\n",
      "        1.0019, 0.9697, 0.9808, 1.0282, 0.9855, 0.9771, 1.0260, 1.0180, 0.9778,\n",
      "        1.0231, 1.0234, 0.9746, 1.0310, 1.0165, 0.9989, 0.9740, 0.9834, 0.9769,\n",
      "        1.0071, 0.9956, 1.0183, 1.0238, 1.0244, 1.0151, 1.0131, 0.9833, 1.0094,\n",
      "        1.0036, 1.0467, 1.0205, 1.0044, 0.9925, 0.9731, 0.9909, 0.9472, 1.0077,\n",
      "        0.9999, 0.9912, 1.0043, 1.0072, 0.9859, 1.0084, 0.9880, 0.9794, 0.9930,\n",
      "        1.0078, 1.0241, 0.9783, 1.0002, 0.9974, 0.9959, 0.9969, 1.0220, 0.9765,\n",
      "        1.0068, 1.0279, 1.0148, 1.0135, 1.0234, 1.0003, 0.9760, 0.9680, 1.0240,\n",
      "        0.9984, 1.0055, 0.9869, 1.0155, 0.9888, 1.0078, 1.0082, 1.0109, 1.0224,\n",
      "        0.9725, 0.9690, 0.9770, 0.9925, 1.0377, 1.0041, 0.9965, 0.9826, 0.9882,\n",
      "        0.9966, 0.9884, 1.0095, 1.0130, 0.9879, 1.0025, 1.0141, 0.9696, 0.9995,\n",
      "        0.9831, 0.9957, 0.9677, 0.9941, 0.9459, 1.0006, 1.0153, 1.0286, 0.9904,\n",
      "        0.9958, 1.0061, 1.0004, 1.0063, 1.0002, 0.9902, 0.9578, 1.0031, 0.9964,\n",
      "        0.9953, 0.9757, 0.9939, 1.0680, 0.9860, 0.9676, 0.9995, 0.9962, 0.9863,\n",
      "        1.0019, 1.0167, 0.9841, 0.9669, 0.9899, 0.9751, 0.9558, 0.9904, 1.0005,\n",
      "        0.9751, 0.9881, 0.9950, 0.9749, 0.9903, 1.0088, 1.0123, 1.0052, 1.0128,\n",
      "        1.0082, 0.9825, 1.0212, 0.9927, 0.9603, 0.9951, 0.9823, 0.9870, 0.9847,\n",
      "        1.0031, 0.9979, 0.9949, 1.0132, 1.0162, 0.9613, 0.9788, 1.0102, 0.9926,\n",
      "        0.9691, 1.0158, 0.9831, 1.0115, 0.9814, 1.0178, 1.0458, 0.9878, 0.9934,\n",
      "        0.9492, 1.0145, 0.9971, 0.9772, 0.9678, 1.0025, 0.9876, 1.0338, 1.0399,\n",
      "        1.0057, 0.9880, 1.0162, 0.9846, 0.9956, 0.9998, 0.9513, 1.0119, 0.9862,\n",
      "        1.0110, 1.0095, 0.9938, 0.9878, 0.9898, 0.9918, 1.0124, 0.9878, 0.9967,\n",
      "        0.9883, 0.9743, 1.0188, 0.9637, 1.0169, 0.9755, 0.9813, 0.9955, 1.0096,\n",
      "        1.0016, 0.9911, 0.9739, 0.9990, 1.0540, 0.9977, 1.0037, 0.9875, 0.9969,\n",
      "        1.0073, 1.0186, 1.0019, 0.9959, 0.9969, 0.9814, 0.9837, 1.0478, 1.0042,\n",
      "        0.9973, 1.0113, 1.0216, 1.0106, 0.9837, 1.0084, 0.9619, 1.0290, 0.9836,\n",
      "        1.0044, 1.0187, 1.0080, 0.9960, 0.9504, 1.0126, 1.0049, 1.0083, 0.9783,\n",
      "        1.0079, 0.9748, 0.9703, 0.9837, 1.0250, 1.0048, 1.0112, 0.9834, 1.0154,\n",
      "        1.0121, 1.0126, 1.0103, 0.9958, 0.9801, 0.9636, 1.0077, 0.9934, 1.0044,\n",
      "        1.0176, 0.9958, 0.9775, 1.0119, 1.0133, 0.9848, 1.0123, 1.0399, 0.9937,\n",
      "        1.0027, 1.0414, 0.9862, 1.0226, 0.9846, 0.9734, 0.9783, 1.0202, 1.0062,\n",
      "        0.9893, 1.0016, 0.9792, 0.9998, 1.0102, 1.0135, 0.9818, 1.0067, 0.9766,\n",
      "        1.0266, 0.9865, 0.9847, 0.9847, 1.0186, 0.9935, 0.9972, 0.9975, 1.0022,\n",
      "        0.9539, 1.0018, 1.0227, 0.9998, 1.0153, 0.9901, 0.9880, 1.0439, 1.0109,\n",
      "        0.9992, 0.9750, 0.9957, 1.0110, 1.0293, 0.9673, 1.0132, 1.0028, 1.0467,\n",
      "        0.9754, 1.0127, 1.0072, 0.9644, 0.9726, 0.9976, 0.9950, 0.9916, 1.0108,\n",
      "        1.0011, 0.9814, 0.9846, 1.0063, 1.0139, 0.9794, 1.0240, 1.0062, 1.0272,\n",
      "        1.0385, 0.9645, 1.0023, 0.9708, 0.9779, 0.9987, 0.9872, 0.9800, 0.9842,\n",
      "        1.0280, 0.9872, 0.9618, 1.0178, 0.9861, 0.9960, 0.9899, 1.0018, 1.0130,\n",
      "        0.9934, 0.9996, 1.0002, 0.9807, 0.9929, 1.0231, 1.0494, 0.9641, 0.9727,\n",
      "        1.0250, 0.9933, 1.0408, 0.9964, 0.9779, 1.0172, 0.9974, 0.9969, 1.0046,\n",
      "        0.9920, 1.0255, 1.0047, 1.0295, 1.0095, 1.0103, 1.0201, 0.9818, 1.0143,\n",
      "        0.9931, 0.9744, 0.9768, 1.0067, 1.0194, 0.9633, 1.0386, 0.9662, 0.9594,\n",
      "        1.0045, 0.9638, 0.9695, 0.9564, 1.0065, 0.9762, 0.9877, 0.9878, 1.0121,\n",
      "        1.0114, 1.0090, 0.9804, 0.9963, 1.0077, 1.0245, 0.9783, 0.9819, 1.0271,\n",
      "        0.9883, 1.0052, 0.9934, 0.9991, 0.9923, 1.0315, 1.0065, 0.9970, 1.0324,\n",
      "        1.0078, 1.0064, 0.9871, 0.9982, 0.9495, 1.0091, 1.0196, 0.9887, 1.0017,\n",
      "        1.0132, 1.0085, 1.0123, 1.0143, 0.9880, 0.9857, 0.9773, 0.9887, 0.9745,\n",
      "        1.0008, 0.9970, 0.9840], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print(model.ssf_scale_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_vit = LoRA_ViT_timm(vit_model=model, r=4, num_classes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 100])\n"
     ]
    }
   ],
   "source": [
    "img = torch.randn(2, 3, 224, 224)\n",
    "pred = lora_vit.forward(img)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/data/hjy/SSF/vit_base_patch16_224_in21k/last.pth.tar'\n",
    "checkpoint = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(\n",
    "        'vit_base_patch16_224_in21k',\n",
    "        pretrained=True,\n",
    "        num_classes=100,\n",
    "        drop_rate=0,\n",
    "        drop_path_rate=0,\n",
    "        global_pool=None,\n",
    "        bn_momentum=None,\n",
    "        bn_eps=None,\n",
    "        scriptable=False,\n",
    "        tuning_mode='ssf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = checkpoint['state_dict']\n",
    "\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 100])\n"
     ]
    }
   ],
   "source": [
    "img = torch.randn(2, 3, 224, 224)\n",
    "pred = model.forward(img)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
